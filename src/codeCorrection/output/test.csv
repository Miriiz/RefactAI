Label;Page;Username;Repo;Commit;Bug;Code
KO;1;ThaUnknown;jassub;8568a346ef951dde7912ea5b04d4ed9aab4cbc9a;fix: create tracks from memory, not FS;"-/* global Module, HEAPU8, FS */
-/* eslint-env browser, worker */
 Module.FS = FS
 
 self.delay = 0 // approximate delay (time of render + postMessage + drawImage), for example 1/60 or 0
@@ -72,11 +71,8 @@ self.setTrack = function ({ content }) {
   // Make sure that the fonts are loaded
   self.writeAvailableFontsToFS(content)
 
-  // Write the subtitle file to the virtual FS.
-  Module.FS.writeFile('/sub.ass', content)
-
   // Tell libass to render the new track
-  self.jassubObj.createTrack('/sub.ass')
   self.ass_track = self.jassubObj.track
   self.renderLoop()
 }"
OK;1;ThaUnknown;jassub;8568a346ef951dde7912ea5b04d4ed9aab4cbc9a;fix: create tracks from memory, not FS;"+/* global Module, HEAPU8, FS, textByteLength */
 Module.FS = FS
 
 self.delay = 0 // approximate delay (time of render + postMessage + drawImage), for example 1/60 or 0
@@ -72,11 +71,8 @@ self.setTrack = function ({ content }) {
   // Make sure that the fonts are loaded
   self.writeAvailableFontsToFS(content)
 
   // Tell libass to render the new track
+  self.jassubObj.createTrackMem(self.subContent, textByteLength(self.subContent))
   self.ass_track = self.jassubObj.track
   self.renderLoop()
 }"
KO;1;ThaUnknown;jassub;8568a346ef951dde7912ea5b04d4ed9aab4cbc9a;fix: create tracks from memory, not FS;"Module.preRun.push(function () {
     }
   }
 
-  if (self.subContent) {
-    Module.FS.writeFile('/sub.ass', self.subContent)
-  }
-
-  self.subContent = null
-
   // Module[""FS""].mount(Module[""FS""].filesystems.IDBFS, {}, '/fonts');
   const fontFiles = self.fontFiles || []
   for (let i = 0; i < fontFiles.length; i++) {
     Module.FS_createPreloadedFile('/fonts', 'font' + i + '-' + fontFiles[i].split('/').pop(), fontFiles[i], true, true)
   }
 })
 
 Module.onRuntimeInitialized = function () {
   self.jassubObj = new Module.JASSub()
 
   self.jassubObj.initLibrary(screen.width, screen.height)
-  self.jassubObj.createTrack('/sub.ass')
   self.jassubObj.setDropAnimations(self.dropAllAnimations)
   self.ass_track = self.jassubObj.track
   self.ass_library = self.jassubObj.ass_library"
OK;1;ThaUnknown;jassub;8568a346ef951dde7912ea5b04d4ed9aab4cbc9a;fix: create tracks from memory, not FS;"Module.preRun.push(function () {
     }
   }
 
   // Module[""FS""].mount(Module[""FS""].filesystems.IDBFS, {}, '/fonts');
   const fontFiles = self.fontFiles || []
   for (let i = 0; i < fontFiles.length; i++) {
     Module.FS_createPreloadedFile('/fonts', 'font' + i + '-' + fontFiles[i].split('/').pop(), fontFiles[i], true, true)
   }
 })
 
+const textByteLength = (input) => new TextEncoder().encode(input).buffer.byteLength
+
 Module.onRuntimeInitialized = function () {
   self.jassubObj = new Module.JASSub()
 
   self.jassubObj.initLibrary(screen.width, screen.height)
+
+  self.jassubObj.createTrackMem(self.subContent, textByteLength(self.subContent))
   self.jassubObj.setDropAnimations(self.dropAllAnimations)
   self.ass_track = self.jassubObj.track
   self.ass_library = self.jassubObj.ass_library"
KO;2;Lunarmagpie;crescent-ext-docstrings;e41817c67bc96f9a5809c0b0eeb6f3ed3fa32b28;fix memory leak;" from __future__ import annotations
 
 from typing import Any
 
 from crescent.commands import decorators
 
@@ -9,13 +11,13 @@
 
 cmd_dec = decorators.command
 
-
 def cursed_command_dec(cls_or_func: Any, *args: Any, **kwargs: Any) -> Any:
 
     meta = cmd_dec(cls_or_func, *args, **kwargs)
 
     if isinstance(cls_or_func, type):
         CLASS_DOCSTRINGS[id(meta)] = cls_or_func.__doc__
 
     return meta
 "
OK;2;Lunarmagpie;crescent-ext-docstrings;e41817c67bc96f9a5809c0b0eeb6f3ed3fa32b28;fix memory leak;" from __future__ import annotations
+import sys
 
 from typing import Any
+from weakref import finalize
 
 from crescent.commands import decorators
 
@@ -9,13 +11,13 @@
 
 cmd_dec = decorators.command
 
 def cursed_command_dec(cls_or_func: Any, *args: Any, **kwargs: Any) -> Any:
 
     meta = cmd_dec(cls_or_func, *args, **kwargs)
 
     if isinstance(cls_or_func, type):
         CLASS_DOCSTRINGS[id(meta)] = cls_or_func.__doc__
+        finalize(meta, CLASS_DOCSTRINGS.pop, id(meta))
 
     return meta
 "
KO;3;unsigned-maki;cherubim-core;886bf1b14083b4727f8d00c5c1d49d61e4e2d0cf;feat(memory): add temporary errors;"def __init__(self, chain, arg_list):
 
     def call(self, args):
         if len(args) == len(arg_list):
             #  TODO: implement resolving of chain
         else:
             #  TODO: implement error
 
 "
OK;3;unsigned-maki;cherubim-core;886bf1b14083b4727f8d00c5c1d49d61e4e2d0cf;feat(memory): add temporary errors;"def __init__(self, chain, arg_list):
 
     def call(self, args):
         if len(args) == len(arg_list):
+            raise ValueError(""Error"")
             #  TODO: implement resolving of chain
         else:
+            raise ValueError(""Error"")
             #  TODO: implement error
 
 "
KO;4;kostaleonard;populare-db-proxy;a1ee90b64c943c8310e3d646f2c4018f8e5c135d;"Added in memory database

Signed-off-by: Leo Kosta <kostaleonard@gmail.com>";" import boto3
 from moto import mock_rds
 from sqlalchemy import Table, Column, Integer, String, MetaData, create_engine
 
 TEST_REGION = ""us-east-2""
 DB_NAME = ""populare_db""
@@ -15,6 +16,7 @@
 MASTER_PASSWORD = ""testingtesting""
 PORT = 3306
 MAX_ALLOCATED_STORAGE_GB = 20
 
 
 @pytest.fixture(name=""aws_credentials"", scope=""session"")
@@ -60,13 +62,18 @@ def fixture_mocked_rds(aws_credentials: None) -> dict:
             MonitoringInterval=0,
             MaxAllocatedStorage=MAX_ALLOCATED_STORAGE_GB
         )
-        print(db_instance)
-        # TODO does this need package mysql-connector to work?
-        url = f""mysql+mysqlconnector://{MASTER_USERNAME}:{MASTER_PASSWORD}@{db_instance['DBInstance']['Endpoint']['Address']}:{PORT}/{db_instance['DBInstance']['DBName']}""
-        print(url)
-        engine = create_engine(url)
-        engine.connect()
-        #engine = create_engine(""mysql:///college.db"")
         meta = MetaData()
         students = Table(
             'students', meta,
@@ -75,4 +82,4 @@ def fixture_mocked_rds(aws_credentials: None) -> dict:
             Column('lastname', String),
         )
         meta.create_all(engine)
-        yield db_instance"
OK;4;kostaleonard;populare-db-proxy;a1ee90b64c943c8310e3d646f2c4018f8e5c135d;"Added in memory database

Signed-off-by: Leo Kosta <kostaleonard@gmail.com>";" import boto3
 from moto import mock_rds
 from sqlalchemy import Table, Column, Integer, String, MetaData, create_engine
+from sqlalchemy.engine import Connection
 
 TEST_REGION = ""us-east-2""
 DB_NAME = ""populare_db""
@@ -15,6 +16,7 @@
 MASTER_PASSWORD = ""testingtesting""
 PORT = 3306
 MAX_ALLOCATED_STORAGE_GB = 20
+TEST_IN_MEM_DB_URL = ""sqlite+pysqlite:///:memory:""
 
 
 @pytest.fixture(name=""aws_credentials"", scope=""session"")
@@ -60,13 +62,18 @@ def fixture_mocked_rds(aws_credentials: None) -> dict:
             MonitoringInterval=0,
             MaxAllocatedStorage=MAX_ALLOCATED_STORAGE_GB
         )
+        yield db_instance
+
+
+@pytest.fixture(name=""local_db"")
+def fixture_local_db() -> Connection:
+    """"""Creates a local SQLite database for testing.
+
+    :return: A connection to the local, in-memory database.
+    """"""
+    engine = create_engine(TEST_IN_MEM_DB_URL)
+    with engine.connect() as conn:
+        # TODO populate the database
         meta = MetaData()
         students = Table(
             'students', meta,
@@ -75,4 +82,4 @@ def fixture_mocked_rds(aws_credentials: None) -> dict:
             Column('lastname', String),
         )
         meta.create_all(engine)
+        yield conn"
KO;4;kostaleonard;populare-db-proxy;a1ee90b64c943c8310e3d646f2c4018f8e5c135d;"Added in memory database

Signed-off-by: Leo Kosta <kostaleonard@gmail.com>";" """"""Tests rds.py.""""""
 
 
 def test_rds_creation(mocked_rds: dict) -> None:
     """"""Tests that the mocked RDS was created successfully.
@@ -9,3 +11,11 @@ def test_rds_creation(mocked_rds: dict) -> None:
     # The mocked RDS instance is created when this test is run.
     # If it was created successfully, there will be no errors in test setup.
     assert True"
OK;4;kostaleonard;populare-db-proxy;a1ee90b64c943c8310e3d646f2c4018f8e5c135d;"Added in memory database

Signed-off-by: Leo Kosta <kostaleonard@gmail.com>";" """"""Tests rds.py.""""""
 
+from sqlalchemy.engine import Connection
+
 
 def test_rds_creation(mocked_rds: dict) -> None:
     """"""Tests that the mocked RDS was created successfully.
@@ -9,3 +11,11 @@ def test_rds_creation(mocked_rds: dict) -> None:
     # The mocked RDS instance is created when this test is run.
     # If it was created successfully, there will be no errors in test setup.
     assert True
+
+
+def test_local_db_creation(local_db: Connection) -> None:
+    """"""Tests that the local database was created successfully.
+
+    :param local_db: A connection to the local, in-memory database.
+    """"""
+    assert True"
KO;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;
OK;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+## Android内存相关
+
+1、dump_meminfo.py
+
+每隔1s读取目标包名的meminfo，并输出到命令行和文件，用于分析和统计一段时间内目标进程的内存占用情况
+
+2、dump_smaps.py
+
+分析原理可见我的博客[Android meminfo 分析](https://dddjjq.github.io/2022/06/15/Android%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90-Code.html)。
+
+主要是读取/proc/{pid}/smaps文件，然后从中读取中Code部分占用的内存分布情况。
+"
KO;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;\ No newline at end of file
OK;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+# 持续dump内存 并保存到文件中
+# python -u ""f:\dump_meminfo.py"" test.log 
+# 支持绝对路径和相对路径
+import os
+import subprocess
+import time
+import re
+import sys
+
+package_name = ""com.tencent.mm""
+command = ""adb shell dumpsys meminfo "" + package_name
+
+# -t total
+# -g graphics
+# -j Java heap
+# -n Native heap
+# -c Code
+dump_type = ""-t""
+
+save_file = None
+
+def dump():
+    global save_file
+    save_file = get_path()
+    if save_file is not None:
+        save_file = open(save_file,""r+"")
+    update_type()
+    write_line(""time is : "" + str(time.time()))
+    count = 0
+    while count < 50:
+        content = exec_command()
+        total = get_total(content,""-t"")
+        graphics = get_total(content,""-g"")
+        java = get_total(content,""-j"")
+        native = get_total(content,""-n"")
+        code = get_total(content,""-c"")
+        res = ""Total  :  "" + total + ""  Graphics  :  "" + graphics + ""  Java  :  "" + java + ""  Native  :  "" + native + ""  Code  :  "" + code
+        write_line(res)
+        time.sleep(1)
+        count += 1
+
+
+def write_line(content):
+    if save_file is not None:
+        save_file.writelines(content + ""\n"")
+    print(content)
+
+def get_path():
+    if (len(sys.argv) <2):
+        return
+    file = sys.argv[1]
+    if os.path.isabs(file):
+        if not os.path.exists(file):
+            fd = os.open(file, os.O_RDWR|os.O_CREAT)
+            os.close(fd)
+        return file
+    cur = os.getcwd()
+    res = cur + os.path.sep + file
+    if not os.path.exists(res):
+        fd = os.open(res, os.O_RDWR|os.O_CREAT)
+        os.close(fd)
+    return res
+
+def update_type():
+    if len(sys.argv) > 2:
+        global dump_type
+        type = sys.argv[2]
+        dump_type = type
+
+
+def save(result,file):
+    pass
+
+def exec_command():
+    try:
+        commands = command.split("" "")
+        out_bytes = subprocess.check_output(commands)
+        out_text = out_bytes.decode('utf-8')
+        return out_text
+    except subprocess.CalledProcessError as e:
+        out_bytes = e.output       # Output generated before error
+        code      = e.returncode   # Return code
+
+def get_total(content,type):
+    lines = content.split('\n')
+    for line in lines:
+        key_word = ""TOTAL""
+        if type == '-t':
+            key_word = ""TOTAL""
+        elif type == '-g':
+            key_word = ""Graphics:""
+        elif type == '-j':
+            key_word = ""Java Heap:""
+        elif type == '-n':
+            key_word = ""Native Heap:""
+        elif type == '-c':
+            key_word = ""Code:""
+        if key_word in line:
+            chars = line.split(key_word)
+            chars = re.split(r""[ ]+"", chars[1])
+            return chars[1]
+
+dump()
\ No newline at end of file"
KO;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;\ No newline at end of file
OK;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+# 根据smaps文件读取进程占用的内存，并将大于[threshold]的占用都罗列出来，便于分析到底是哪个模块占用内存过多
+# 目前只有Code模块
+# 需要root权限
+
+# python -u ""f:\parse_smaps.py"" temp.log
+
+import os
+import sys
+import re
+import subprocess
+
+# 可以配置的内容
+# smaps_temp指的是smaps文件
+# package_name remote_name代表包名
+# threshold代表最小统计大小
+smaps_temp = r""F:\smaps.txt""
+package_name = ""com.tencent.mm""
+remote_name = package_name + "":remote""
+threshold = 1000
+
+ps_cmd = ""adb shell ps -A | grep "" + package_name
+
+# android.os.Debug getSummaryCode -> android_os_Debug android_os_Debug_getMemInfo
+# getOtherPrivate(OTHER_SO)
+#   + getOtherPrivate(OTHER_JAR)
+#   + getOtherPrivate(OTHER_APK)
+#   + getOtherPrivate(OTHER_TTF)
+#   + getOtherPrivate(OTHER_DEX)
+#   + getOtherPrivate(OTHER_OAT)
+#   + getOtherPrivate(OTHER_DALVIK_OTHER_ZYGOTE_CODE_CACHE)
+#   + getOtherPrivate(OTHER_DALVIK_OTHER_APP_CODE_CACHE);
+end_list = [
+    "".so"",
+    "".jar"",
+    "".apk"",
+    "".ttf"",
+    "".odex"",
+    "".vdex"",
+    "".oat"",
+    "".art"","".art]"",
+]
+
+start_list = [
+    ""/memfd:jit-cache"",
+    ""[anon:dalvik-jit-code-cache"",
+    ""[anon:dalvik-data-code-cache"",
+    ""/dev/ashmem/jit-zygote-cache"",
+    ""/memfd:jit-zygote-cache"",
+    "".dex""
+]
+
+save_file = None
+
+def get_pid():
+    res = exec_command(ps_cmd)
+    lines = res.split('\n')
+    for line in lines:
+        if (remote_name not in line) and (package_name in line):
+            pid = re.split(r""[ ]+"", line)[1]
+            return pid
+
+def exec_command(command):
+    try:
+        commands = command.split("" "")
+        out_bytes = subprocess.check_output(commands)
+        out_text = out_bytes.decode('utf-8')
+        return out_text
+    except subprocess.CalledProcessError as e:
+        out_bytes = e.output       # Output generated before error
+        code      = e.returncode   # Return code
+
+def parse():
+    pid = get_pid()
+    print(pid)
+    global save_file
+    save_file = get_path()
+    if save_file is not None:
+        save_file = open(save_file,""r+"")
+    save_info(""pid is "" + str(pid) + ""\n"")
+    smaps = exec_command(""adb shell cat /proc/"" + pid + ""/smaps"")
+    write_origin_smaps(smaps)
+    smaps = smaps.split(""\n"")
+    parse_code(smaps)
+
+def write_origin_smaps(data):
+    fd = os.open(smaps_temp, os.O_RDWR|os.O_CREAT)
+    os.write(fd, data.encode())
+
+def get_path():
+    if (len(sys.argv) <2):
+        return
+    file = sys.argv[1]
+    if os.path.isabs(file):
+        if not os.path.exists(file):
+            fd = os.open(file, os.O_RDWR|os.O_CREAT)
+            os.close(fd)
+        return file
+    cur = os.getcwd()
+    res = cur + os.path.sep + file
+    if not os.path.exists(res):
+        fd = os.open(res, os.O_RDWR|os.O_CREAT)
+        os.close(fd)
+    return res
+
+# android_os_Debug.cpp [load_maps]
+def parse_code(lines):
+    count = 0
+    total = 0
+    pending_line = None
+    for line in lines:
+        if count <= 0:
+            for filter in end_list:
+                if line.strip().endswith(filter):
+                    count = 2
+                    pending_line = line
+            for start in start_list:
+                if start in line:
+                    count = 2
+                    pending_line = line
+        if count > 0 and (line.startswith(""Private_Clean"") or line.startswith(""Private_Dirty"")):
+            value = get_value(line)
+            if int(value) > threshold and pending_line is not None:
+                save_info(pending_line)
+                save_info(line)
+                pass
+            total = total + int(value)
+            count = count - 1
+            if count == 0:
+                pending_line = None
+    save_info(""total code is "" + str(total))
+    if save_file is not None:
+        save_file.close()
+
+def save_info(line):
+    print(line)
+    if save_file is not None:
+        save_file.writelines(line)
+
+def get_value(line):
+    return re.split(r""[ ]+"", line)[1]
+
+if __name__ == ""__main__"":
+    parse()
\ No newline at end of file"
KO;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;
OK;8;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+## 辅助脚本
+
+一些辅助工具脚本，以期提升开发效率以及Debug效率
+"
KO;10;tongzhangHIT;memory_control;e71d707c3173f3f10dc8b8c4daf1d520c1e031cf;replace memory_info().vms with .rss;"def _worker(self):
                 if self._verification_criteria(proc):
 #                    print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),end='')
 #                    print(""dwm kill, memory %d Byte"" %(proc.memory_info().vms))
-                    logger.debug(""dwm memory %d MB, KILL"" %(proc.memory_info().vms / 1024 / 1024))
                     proc.kill()
             except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                 pass
@@ -84,5 +85,5 @@ def tick(self):
 if __name__ == ""__main__"":
     process_for_controlled = ProcessCriteria()
     process_for_controlled.name = ""dwm.exe""
-    process_for_controlled.max_vms_mb = 1024
     controller = ControlProcesses(process_for_controlled)"
OK;10;tongzhangHIT;memory_control;e71d707c3173f3f10dc8b8c4daf1d520c1e031cf;replace memory_info().vms with .rss;"def _worker(self):
                 if self._verification_criteria(proc):
 #                    print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),end='')
 #                    print(""dwm kill, memory %d Byte"" %(proc.memory_info().vms))
+                    logger.debug(""dwm memory %d MB, KILL"" %(proc.memory_info().rss / 1024 / 1024))
+                    #vms，进程使用的虚拟内存；rss，进程使用实际物理内存
                     proc.kill()
             except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                 pass
@@ -84,5 +85,5 @@ def tick(self):
 if __name__ == ""__main__"":
     process_for_controlled = ProcessCriteria()
     process_for_controlled.name = ""dwm.exe""
+    process_for_controlled.max_vms_mb = 2048
     controller = ControlProcesses(process_for_controlled)"
KO;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;
OK;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+## Android内存相关
+
+1、dump_meminfo.py
+
+每隔1s读取目标包名的meminfo，并输出到命令行和文件，用于分析和统计一段时间内目标进程的内存占用情况
+
+2、dump_smaps.py
+
+分析原理可见我的博客[Android meminfo 分析](https://dddjjq.github.io/2022/06/15/Android%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90-Code.html)。
+
+主要是读取/proc/{pid}/smaps文件，然后从中读取中Code部分占用的内存分布情况。
+"
KO;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;\ No newline at end of file
OK;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+# 持续dump内存 并保存到文件中
+# python -u ""f:\dump_meminfo.py"" test.log 
+# 支持绝对路径和相对路径
+import os
+import subprocess
+import time
+import re
+import sys
+
+package_name = ""com.tencent.mm""
+command = ""adb shell dumpsys meminfo "" + package_name
+
+# -t total
+# -g graphics
+# -j Java heap
+# -n Native heap
+# -c Code
+dump_type = ""-t""
+
+save_file = None
+
+def dump():
+    global save_file
+    save_file = get_path()
+    if save_file is not None:
+        save_file = open(save_file,""r+"")
+    update_type()
+    write_line(""time is : "" + str(time.time()))
+    count = 0
+    while count < 50:
+        content = exec_command()
+        total = get_total(content,""-t"")
+        graphics = get_total(content,""-g"")
+        java = get_total(content,""-j"")
+        native = get_total(content,""-n"")
+        code = get_total(content,""-c"")
+        res = ""Total  :  "" + total + ""  Graphics  :  "" + graphics + ""  Java  :  "" + java + ""  Native  :  "" + native + ""  Code  :  "" + code
+        write_line(res)
+        time.sleep(1)
+        count += 1
+
+
+def write_line(content):
+    if save_file is not None:
+        save_file.writelines(content + ""\n"")
+    print(content)
+
+def get_path():
+    if (len(sys.argv) <2):
+        return
+    file = sys.argv[1]
+    if os.path.isabs(file):
+        if not os.path.exists(file):
+            fd = os.open(file, os.O_RDWR|os.O_CREAT)
+            os.close(fd)
+        return file
+    cur = os.getcwd()
+    res = cur + os.path.sep + file
+    if not os.path.exists(res):
+        fd = os.open(res, os.O_RDWR|os.O_CREAT)
+        os.close(fd)
+    return res
+
+def update_type():
+    if len(sys.argv) > 2:
+        global dump_type
+        type = sys.argv[2]
+        dump_type = type
+
+
+def save(result,file):
+    pass
+
+def exec_command():
+    try:
+        commands = command.split("" "")
+        out_bytes = subprocess.check_output(commands)
+        out_text = out_bytes.decode('utf-8')
+        return out_text
+    except subprocess.CalledProcessError as e:
+        out_bytes = e.output       # Output generated before error
+        code      = e.returncode   # Return code
+
+def get_total(content,type):
+    lines = content.split('\n')
+    for line in lines:
+        key_word = ""TOTAL""
+        if type == '-t':
+            key_word = ""TOTAL""
+        elif type == '-g':
+            key_word = ""Graphics:""
+        elif type == '-j':
+            key_word = ""Java Heap:""
+        elif type == '-n':
+            key_word = ""Native Heap:""
+        elif type == '-c':
+            key_word = ""Code:""
+        if key_word in line:
+            chars = line.split(key_word)
+            chars = re.split(r""[ ]+"", chars[1])
+            return chars[1]
+
+dump()
\ No newline at end of file"
KO;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;\ No newline at end of file
OK;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+# 根据smaps文件读取进程占用的内存，并将大于[threshold]的占用都罗列出来，便于分析到底是哪个模块占用内存过多
+# 目前只有Code模块
+# 需要root权限
+
+# python -u ""f:\parse_smaps.py"" temp.log
+
+import os
+import sys
+import re
+import subprocess
+
+# 可以配置的内容
+# smaps_temp指的是smaps文件
+# package_name remote_name代表包名
+# threshold代表最小统计大小
+smaps_temp = r""F:\smaps.txt""
+package_name = ""com.tencent.mm""
+remote_name = package_name + "":remote""
+threshold = 1000
+
+ps_cmd = ""adb shell ps -A | grep "" + package_name
+
+# android.os.Debug getSummaryCode -> android_os_Debug android_os_Debug_getMemInfo
+# getOtherPrivate(OTHER_SO)
+#   + getOtherPrivate(OTHER_JAR)
+#   + getOtherPrivate(OTHER_APK)
+#   + getOtherPrivate(OTHER_TTF)
+#   + getOtherPrivate(OTHER_DEX)
+#   + getOtherPrivate(OTHER_OAT)
+#   + getOtherPrivate(OTHER_DALVIK_OTHER_ZYGOTE_CODE_CACHE)
+#   + getOtherPrivate(OTHER_DALVIK_OTHER_APP_CODE_CACHE);
+end_list = [
+    "".so"",
+    "".jar"",
+    "".apk"",
+    "".ttf"",
+    "".odex"",
+    "".vdex"",
+    "".oat"",
+    "".art"","".art]"",
+]
+
+start_list = [
+    ""/memfd:jit-cache"",
+    ""[anon:dalvik-jit-code-cache"",
+    ""[anon:dalvik-data-code-cache"",
+    ""/dev/ashmem/jit-zygote-cache"",
+    ""/memfd:jit-zygote-cache"",
+    "".dex""
+]
+
+save_file = None
+
+def get_pid():
+    res = exec_command(ps_cmd)
+    lines = res.split('\n')
+    for line in lines:
+        if (remote_name not in line) and (package_name in line):
+            pid = re.split(r""[ ]+"", line)[1]
+            return pid
+
+def exec_command(command):
+    try:
+        commands = command.split("" "")
+        out_bytes = subprocess.check_output(commands)
+        out_text = out_bytes.decode('utf-8')
+        return out_text
+    except subprocess.CalledProcessError as e:
+        out_bytes = e.output       # Output generated before error
+        code      = e.returncode   # Return code
+
+def parse():
+    pid = get_pid()
+    print(pid)
+    global save_file
+    save_file = get_path()
+    if save_file is not None:
+        save_file = open(save_file,""r+"")
+    save_info(""pid is "" + str(pid) + ""\n"")
+    smaps = exec_command(""adb shell cat /proc/"" + pid + ""/smaps"")
+    write_origin_smaps(smaps)
+    smaps = smaps.split(""\n"")
+    parse_code(smaps)
+
+def write_origin_smaps(data):
+    fd = os.open(smaps_temp, os.O_RDWR|os.O_CREAT)
+    os.write(fd, data.encode())
+
+def get_path():
+    if (len(sys.argv) <2):
+        return
+    file = sys.argv[1]
+    if os.path.isabs(file):
+        if not os.path.exists(file):
+            fd = os.open(file, os.O_RDWR|os.O_CREAT)
+            os.close(fd)
+        return file
+    cur = os.getcwd()
+    res = cur + os.path.sep + file
+    if not os.path.exists(res):
+        fd = os.open(res, os.O_RDWR|os.O_CREAT)
+        os.close(fd)
+    return res
+
+# android_os_Debug.cpp [load_maps]
+def parse_code(lines):
+    count = 0
+    total = 0
+    pending_line = None
+    for line in lines:
+        if count <= 0:
+            for filter in end_list:
+                if line.strip().endswith(filter):
+                    count = 2
+                    pending_line = line
+            for start in start_list:
+                if start in line:
+                    count = 2
+                    pending_line = line
+        if count > 0 and (line.startswith(""Private_Clean"") or line.startswith(""Private_Dirty"")):
+            value = get_value(line)
+            if int(value) > threshold and pending_line is not None:
+                save_info(pending_line)
+                save_info(line)
+                pass
+            total = total + int(value)
+            count = count - 1
+            if count == 0:
+                pending_line = None
+    save_info(""total code is "" + str(total))
+    if save_file is not None:
+        save_file.close()
+
+def save_info(line):
+    print(line)
+    if save_file is not None:
+        save_file.writelines(line)
+
+def get_value(line):
+    return re.split(r""[ ]+"", line)[1]
+
+if __name__ == ""__main__"":
+    parse()
\ No newline at end of file"
KO;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;
OK;18;dddjjq;ScriptTools;72bfcf4c54a8ef58f74f85de150610fac298e17a;Add some android memory scripts;"+## 辅助脚本
+
+一些辅助工具脚本，以期提升开发效率以及Debug效率
+"
KO;27;aelbozie;food-pov-hack;6022bfa92dcbcf17b45bc26722047ca523e74384;"Merge pull request #8 from aelbozie/fix-heroku-frontend

try fixing memory issue";" build:
   docker:
-    web: Dockerfile.python"
OK;27;aelbozie;food-pov-hack;6022bfa92dcbcf17b45bc26722047ca523e74384;"Merge pull request #8 from aelbozie/fix-heroku-frontend

try fixing memory issue";" build:
   docker:
+    web: Dockerfile.node
+    worker: Dockerfile.python"
KO;27;aelbozie;food-pov-hack;6022bfa92dcbcf17b45bc26722047ca523e74384;"Merge pull request #8 from aelbozie/fix-heroku-frontend

try fixing memory issue";"     ""web-vitals"": ""^2.1.4""
   },
   ""scripts"": {
-    ""start"": ""react-scripts start"",
-    ""build"": ""react-scripts build"",
-    ""test"": ""react-scripts test"",
-    ""eject"": ""react-scripts eject""
   },
   ""eslintConfig"": {
     ""extends"": ["
OK;27;aelbozie;food-pov-hack;6022bfa92dcbcf17b45bc26722047ca523e74384;"Merge pull request #8 from aelbozie/fix-heroku-frontend

try fixing memory issue";"     ""web-vitals"": ""^2.1.4""
   },
   ""scripts"": {
+    ""start"": ""node --optimize_for_size --max_old_space_size=2560 node_modules/.bin/react-scripts start"",
+    ""build"": ""node --optimize_for_size --max_old_space_size=2560 react-scripts build"",
+    ""test"": ""node --optimize_for_size --max_old_space_size=2560 react-scripts test"",
+    ""eject"": ""node --optimize_for_size --max_old_space_size=2560 react-scripts eject""
   },
   ""eslintConfig"": {
     ""extends"": ["
KO;27;aelbozie;food-pov-hack;1033f0ed66ffdeebd83645c2a2728f54405f55a3;try fixing memory issue;" build:
   docker:
-    web: Dockerfile.python"
OK;27;aelbozie;food-pov-hack;1033f0ed66ffdeebd83645c2a2728f54405f55a3;try fixing memory issue;" build:
   docker:
+    web: Dockerfile.node
+    worker: Dockerfile.python"
KO;27;aelbozie;food-pov-hack;1033f0ed66ffdeebd83645c2a2728f54405f55a3;try fixing memory issue;"     ""web-vitals"": ""^2.1.4""
   },
   ""scripts"": {
-    ""start"": ""react-scripts start"",
-    ""build"": ""react-scripts build"",
-    ""test"": ""react-scripts test"",
-    ""eject"": ""react-scripts eject""
   },
   ""eslintConfig"": {
     ""extends"": ["
OK;27;aelbozie;food-pov-hack;1033f0ed66ffdeebd83645c2a2728f54405f55a3;try fixing memory issue;"     ""web-vitals"": ""^2.1.4""
   },
   ""scripts"": {
+    ""start"": ""node --optimize_for_size --max_old_space_size=2560 node_modules/.bin/react-scripts start"",
+    ""build"": ""node --optimize_for_size --max_old_space_size=2560 react-scripts build"",
+    ""test"": ""node --optimize_for_size --max_old_space_size=2560 react-scripts test"",
+    ""eject"": ""node --optimize_for_size --max_old_space_size=2560 react-scripts eject""
   },
   ""eslintConfig"": {
     ""extends"": ["
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;\ No newline at end of file
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+
+# Created by https://www.gitignore.io/api/osx,linux,python,windows,pycharm,visualstudiocode
+
+### Linux ###
+*~
+
+# temporary files which can be created if a process still has a handle open of a deleted file
+.fuse_hidden*
+
+# KDE directory preferences
+.directory
+
+# Linux trash folder which might appear on any partition or disk
+.Trash-*
+
+# .nfs files are created when an open file is removed but is still being accessed
+.nfs*
+
+### OSX ###
+*.DS_Store
+.AppleDouble
+.LSOverride
+
+# Icon must end with two \r
+Icon
+
+# Thumbnails
+._*
+
+# Files that might appear in the root of a volume
+.DocumentRevisions-V100
+.fseventsd
+.Spotlight-V100
+.TemporaryItems
+.Trashes
+.VolumeIcon.icns
+.com.apple.timemachine.donotpresent
+
+# Directories potentially created on remote AFP share
+.AppleDB
+.AppleDesktop
+Network Trash Folder
+Temporary Items
+.apdisk
+
+### PyCharm ###
+# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio and Webstorm
+# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839
+
+# User-specific stuff:
+.idea/**/workspace.xml
+.idea/**/tasks.xml
+.idea/dictionaries
+
+# Sensitive or high-churn files:
+.idea/**/dataSources/
+.idea/**/dataSources.ids
+.idea/**/dataSources.xml
+.idea/**/dataSources.local.xml
+.idea/**/sqlDataSources.xml
+.idea/**/dynamic.xml
+.idea/**/uiDesigner.xml
+
+# Gradle:
+.idea/**/gradle.xml
+.idea/**/libraries
+
+# CMake
+cmake-build-debug/
+
+# Mongo Explorer plugin:
+.idea/**/mongoSettings.xml
+
+## File-based project format:
+*.iws
+
+## Plugin-specific files:
+
+# IntelliJ
+/out/
+
+# mpeltonen/sbt-idea plugin
+.idea_modules/
+
+# JIRA plugin
+atlassian-ide-plugin.xml
+
+# Cursive Clojure plugin
+.idea/replstate.xml
+
+# Ruby plugin and RubyMine
+/.rakeTasks
+
+# Crashlytics plugin (for Android Studio and IntelliJ)
+com_crashlytics_export_strings.xml
+crashlytics.properties
+crashlytics-build.properties
+fabric.properties
+
+### PyCharm Patch ###
+# Comment Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-215987721
+
+# *.iml
+# modules.xml
+# .idea/misc.xml
+# *.ipr
+
+# Sonarlint plugin
+.idea/sonarlint
+
+### Python ###
+# Byte-compiled / optimized / DLL files
+__pycache__/
+*.py[cod]
+*$py.class
+
+# C extensions
+*.so
+
+# Distribution / packaging
+.Python
+build/
+develop-eggs/
+dist/
+downloads/
+eggs/
+.eggs/
+lib/
+lib64/
+parts/
+sdist/
+var/
+wheels/
+*.egg-info/
+.installed.cfg
+*.egg
+
+# PyInstaller
+#  Usually these files are written by a python script from a template
+#  before PyInstaller builds the exe, so as to inject date/other infos into it.
+*.manifest
+*.spec
+
+# Installer logs
+pip-log.txt
+pip-delete-this-directory.txt
+
+# Unit test / coverage reports
+htmlcov/
+.tox/
+.coverage
+.coverage.*
+.cache
+.pytest_cache/
+nosetests.xml
+coverage.xml
+*.cover
+.hypothesis/
+
+# Translations
+*.mo
+*.pot
+
+# Flask stuff:
+instance/
+.webassets-cache
+
+# Scrapy stuff:
+.scrapy
+
+# Sphinx documentation
+docs/_build/
+
+# PyBuilder
+target/
+
+# Jupyter Notebook
+.ipynb_checkpoints
+
+# pyenv
+.python-version
+
+# celery beat schedule file
+celerybeat-schedule.*
+
+# SageMath parsed files
+*.sage.py
+
+# Environments
+.env
+.venv
+env/
+venv/
+ENV/
+env.bak/
+venv.bak/
+
+# Spyder project settings
+.spyderproject
+.spyproject
+
+# Rope project settings
+.ropeproject
+
+# mkdocs documentation
+/site
+
+# mypy
+.mypy_cache/
+
+### VisualStudioCode ###
+.vscode/*
+!.vscode/settings.json
+!.vscode/tasks.json
+!.vscode/launch.json
+!.vscode/extensions.json
+.history
+
+### Windows ###
+# Windows thumbnail cache files
+Thumbs.db
+ehthumbs.db
+ehthumbs_vista.db
+
+# Folder config file
+Desktop.ini
+
+# Recycle Bin used on file shares
+$RECYCLE.BIN/
+
+# Windows Installer files
+*.cab
+*.msi
+*.msm
+*.msp
+
+# Windows shortcuts
+*.lnk
+
+# Build folder
+
+*/build/*
+
+# End of https://www.gitignore.io/api/osx,linux,python,windows,pycharm,visualstudiocode
\ No newline at end of file"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+# aws_sam_ocr
+This is an AWS SAM app that uses Rekognition APIs to detect text in S3 Objects and stores labels in DynamoDB.
+
+## Project structure
+Here is a brief overview of what we have generated for you.
+```bash
+.
+├── README.md                   <-- This instructions file
+├── src                         <-- Source code for the Lambda function
+│   ├── __init__.py
+│   └── app.py                  <-- Lambda function code
+├── template.yaml               <-- SAM template
+└── SampleEvent.json            <-- Sample S3 event
+```
+
+
+## Requirements
+* AWS CLI
+* [Python 3.6 installed](https://www.python.org/downloads/)
+* [Docker installed](https://www.docker.com/community-edition)
+* [Python Virtual Environment](http://docs.python-guide.org/en/latest/dev/virtualenvs/)
+
+
+## CLI Commands to package and deploy your application
+CLI commands to package, deploy and describe outputs defined within the cloudformation stack.
+
+First, we need an `S3 bucket` where we can upload our Lambda functions packaged as ZIP before we deploy anything - If you don't have a S3 bucket to store code artifacts then this is a good time to create one:
+
+```bash
+aws s3 mb s3://BUCKET_NAME
+```
+
+Next, run the following command to package your Lambda function. The `sam package` command creates a deployment package (ZIP file) containing your code and dependencies, and uploads them to the S3 bucket you specify. 
+
+```bash
+sam package \
+    --template-file template.yaml \
+    --output-template-file packaged.yaml \
+    --s3-bucket REPLACE_THIS_WITH_YOUR_S3_BUCKET_NAME
+```
+
+The `sam deploy` command will create a Cloudformation Stack and deploy your SAM resources.
+```bash
+sam deploy \
+    --template-file packaged.yaml \
+    --stack-name aws_sam_ocr \
+    --capabilities CAPABILITY_IAM \
+    --parameter-overrides MyParameterSample=MySampleValue
+```
+
+To see the names of the S3 bucket and DynamoDB table created after deployment, you can use the `aws cloudformation describe-stacks` command.
+```bash
+aws cloudformation describe-stacks \
+    --stack-name aws_sam_ocr --query 'Stacks[].Outputs'
+```"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+{
+    ""Records"": [
+        {
+            ""eventVersion"": ""2.0"", 
+            ""eventName"": ""ObjectCreated:Put"", 
+            ""eventTime"": ""1970-01-01T00:00:00.000Z"", 
+            ""userIdentity"": {
+                ""principalId"": ""EXAMPLE""
+            }, 
+            ""eventSource"": ""aws:s3"", 
+            ""requestParameters"": {
+                ""sourceIPAddress"": ""127.0.0.1""
+            }, 
+            ""s3"": {
+                ""configurationId"": ""testConfigRule"", 
+                ""object"": {
+                    ""eTag"": ""1c43a0c9dcc31572b5e49c0b42f8b17f"", 
+                    ""key"": ""INSERT FILENAME HERE (e.g. receipt.png)"", 
+                    ""sequencer"": ""0A1B2C3D4E5F678901"", 
+                    ""size"": 1024
+                }, 
+                ""bucket"": {
+                    ""ownerIdentity"": {
+                        ""principalId"": ""EXAMPLE""
+                    }, 
+                    ""name"": ""INSERT BUCKET NAME HERE (e.g. aws-sam-ocr-sourceimagebucket-123122312)"", 
+                    ""arn"": ""arn:aws:s3:::INSERT BUCKET NAME HERE (e.g. aws-sam-ocr-sourceimagebucket-123122312)""
+                }, 
+                ""s3SchemaVersion"": ""1.0""
+            }, 
+            ""responseElements"": {
+                ""x-amz-id-2"": ""EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH"", 
+                ""x-amz-request-id"": ""EXAMPLE123456789""
+            }, 
+            ""awsRegion"": ""us-east-1""
+        }
+    ]
+}"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;\ No newline at end of file
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+version: 0.2 
+# Buildspec Reference Doc: https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec-ref-syntax
+# run-as: Linux-user-name
+
+# env: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.env
+#   shell: shell-tag
+#   variables:
+#     key: ""value""
+#     key: ""value""
+#   parameter-store:
+#     key: ""value""
+#     key: ""value""
+#   exported-variables:
+#     - variable
+#     - variable
+#   secrets-manager:
+#     key: secret-id:json-key:version-stage:version-id
+#   git-credential-helper: no | yes
+
+# proxy: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.proxy
+#   upload-artifacts: no | yes
+#   logs: no | yes
+
+# batch: # https://docs.aws.amazon.com/codebuild/latest/userguide/batch-build-buildspec.html#build-spec.batch
+  # fast-fail: false | true
+  # build-list:
+  # build-matrix:
+  # build-graph:
+        
+phases:
+  install:
+    # run-as: Linux-user-name
+    # on-failure: ABORT | CONTINUE
+    runtime-versions:
+      python: 3.8
+    #   runtime: version
+    # commands:
+    #   - command
+    #   - command
+    # finally:
+    #   - command
+    #   - command
+  # pre_build:
+    # run-as: Linux-user-name
+    # on-failure: ABORT | CONTINUE
+    # commands:
+    #   - command
+    #   - command
+    # finally:
+    #   - command
+    #   - command
+  build:
+    # run-as: Linux-user-name
+    on-failure: ABORT
+    commands:
+      - echo ""Starting SAM packaging `date` in `pwd`""
+      - aws cloudformation package --template-file template.yaml --s3-bucket $BUILD_OUTPUT_BUCKET --output-template-file packaged.yaml
+    # finally:
+    #   - command
+    #   - command
+  post_build:
+    # run-as: Linux-user-name
+    # on-failure: ABORT | CONTINUE
+    commands:
+      - echo ""SAM packaging completed on `date`""
+    # finally:
+    #   - command
+    #   - command
+
+# reports: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.reports
+#   report-group-name-or-arn:
+#     files:
+#       - location
+#       - location
+#     base-directory: location
+#     discard-paths: no | yes
+#     file-format: report-format
+artifacts: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.artifacts
+  files:
+    - packaged.yaml
+    # - location
+  name: artifact-name
+  discard-paths: yes
+  # base-directory: location
+  # exclude-paths: excluded paths
+  # enable-symlinks: no | yes
+  # s3-prefix: prefix
+  # secondary-artifacts:
+  #   artifactIdentifier:
+  #     files:
+  #       - location
+  #       - location
+  #     name: secondary-artifact-name
+  #     discard-paths: no | yes
+  #     base-directory: location
+  #   artifactIdentifier:
+  #     files:
+  #       - location
+  #       - location
+  #     discard-paths: no | yes
+  #     base-directory: location
+# cache: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.cache
+#   paths:
+#     # - path
+#     # - path
\ No newline at end of file"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+AWSTemplateFormatVersion: '2010-09-09'
+Transform: AWS::Serverless-2016-10-31
+Description: SAM app that uses Rekognition APIs to detect text in S3 Objects and stores
+  labels in DynamoDB.
+Resources:
+  DetectTextInImage:
+    Type: AWS::Serverless::Function
+    Properties:
+      Handler: src/app.lambda_handler
+      Runtime: python3.9
+      CodeUri: s3://ej-mv-us-east-1-other/76ed19fc66c2bb627e4611d44b1b5257
+      Description: Uses Rekognition APIs to detect text in S3 Objects and stores the
+        text and labels in DynamoDB.
+      MemorySize: 512
+      Timeout: 30
+      Environment:
+        Variables:
+          TABLE_NAME:
+            Ref: ResultsTable
+      Policies:
+      - Version: '2012-10-17'
+        Statement:
+        - Effect: Allow
+          Action:
+          - s3:GetObject
+          Resource: arn:aws:s3:::*
+        - Effect: Allow
+          Action:
+          - s3:PutObject
+          Resource:
+            Fn::GetAtt:
+            - FailedImageBucket
+            - Arn
+        - Effect: Allow
+          Action:
+          - rekognition:DetectText
+          - rekognition:DetectLabels
+          Resource: '*'
+        - Effect: Allow
+          Action:
+          - dynamodb:GetItem
+          - dynamodb:PutItem
+          - dynamodb:Scan
+          - dynamodb:UpdateItem
+          Resource:
+            Fn::Join:
+            - ''
+            - - 'arn:aws:dynamodb:'
+              - Ref: AWS::Region
+              - ':'
+              - Ref: AWS::AccountId
+              - :table/
+              - Ref: ResultsTable
+      Events:
+        BucketEvent1:
+          Type: S3
+          Properties:
+            Bucket:
+              Ref: SourceImageBucket
+            Events:
+            - s3:ObjectCreated:*
+    Metadata:
+      SamResourceId: DetectTextInImage
+  SourceImageBucket:
+    Type: AWS::S3::Bucket
+    Metadata:
+      SamResourceId: SourceImageBucket
+  FailedImageBucket:
+    Type: AWS::S3::Bucket
+    Metadata:
+      SamResourceId: FailedImageBucket
+  ResultsTable:
+    Type: AWS::Serverless::SimpleTable
+    Metadata:
+      SamResourceId: ResultsTable"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+# aws-sam-ocr-pipeline
+
+**This is an example of how to create a minimal pipeline for SAM based Serverless Apps**
+
+![Pipeline Sample Image](pipeline-sample.png)
+
+## Requirements
+
+* AWS CLI already configured with Administrator access 
+    - Alternatively, you can use a [Cloudformation Service Role with Admin access](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-servicerole.html)
+* [Github Personal Token](https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/) with full permissions on **admin:repo_hook and repo**
+
+## Configuring GitHub Integration
+
+This Pipeline is configured to look up for GitHub information stored on [EC2 System Manager Parameter Store](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html) such as Branch, Repo, Username and OAuth Token.
+
+Replace the placeholders with values corresponding to your GitHub Repo and Token:
+
+```bash
+aws ssm put-parameter \
+    --name ""/service/aws-sam-ocr-pipeline/github/repo"" \
+    --description ""Github Repository name for Cloudformation Stack aws-sam-ocr-pipeline-pipeline"" \
+    --type ""String"" \
+    --value ""GITHUB_REPO_NAME""
+
+aws ssm put-parameter \
+    --name ""/service/aws-sam-ocr-pipeline/github/token"" \
+    --description ""Github Token for Cloudformation Stack aws-sam-ocr-pipeline-pipeline"" \
+    --type ""String"" \
+    --value ""TOKEN""
+
+aws ssm put-parameter \
+    --name ""/service/aws-sam-ocr-pipeline/github/user"" \
+    --description ""Github Username for Cloudformation Stack aws-sam-ocr-pipeline-pipeline"" \
+    --type ""String"" \
+    --value ""GITHUB_USER""
+```
+
+**NOTE:** Keep in mind that these Parameters will only be available within the same region you're deploying this Pipeline stack. Also, if these values ever change you will need to [update these parameters](https://docs.aws.amazon.com/cli/latest/reference/ssm/put-parameter.html) as well as update the ""aws-sam-ocr-pipeline-pipeline"" Cloudformation stack.
+
+## Pipeline creation
+
+<details>
+<summary>If you don't use Python or don't want to trigger the Pipeline from the `master` branch click here...</summary>
+Before we create this 3-environment Pipeline through Cloudformation you may want to change a couple of things to fit your environment/runtime:
+
+* **CodeBuild** uses a `Python` build image by default and if you're not using `Python` as a runtime you can change that
+    - [CodeBuild offers multiple images](https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html) and you can  update the `Image` property under `pipeline.yaml` file accordingly
+
+```yaml
+    CodeBuildProject:
+        Type: AWS::CodeBuild::Project
+        Properties:
+            ...
+            Environment: 
+                Type: LINUX_CONTAINER
+                ComputeType: BUILD_GENERAL1_SMALL
+                Image: aws/codebuild/python:3.6.5 # More info on Images: https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html
+                EnvironmentVariables:
+                  - 
+                    Name: BUILD_OUTPUT_BUCKET
+                    Value: !Ref BuildArtifactsBucket
+...
+```
+
+* **CodePipeline** uses the `master` branch to trigger the CI/CD pipeline and if you want to specify another branch you can do so by updating the following section in the `pipeline.yaml` file.
+```yaml
+    Stages:
+        - Name: Source
+            Actions:
+            - Name: SourceCodeRepo
+                ActionTypeId:
+                # More info on Possible Values: https://docs.aws.amazon.com/codepipeline/latest/userguide/reference-pipeline-structure.html#action-requirements
+                Category: Source
+                Owner: ThirdParty
+                Provider: GitHub
+                Version: ""1""
+                Configuration:
+                Owner: !Ref GithubUser
+                Repo: !Ref GithubRepo
+                Branch: master
+                OAuthToken: !Ref GithubToken
+                OutputArtifacts:
+                - Name: SourceCodeAsZip
+                RunOrder: 1
+```
+</details>
+
+Run the following AWS CLI command to create your first pipeline for your SAM based Serverless App:
+
+```bash
+aws cloudformation create-stack \
+    --stack-name aws-sam-ocr-pipeline-pipeline \
+    --template-body file://pipeline.yaml \
+    --capabilities CAPABILITY_NAMED_IAM
+```
+
+This may take a couple of minutes to complete, therefore give it a minute or two and then run the following command to retrieve the Git repository:
+
+```bash
+aws cloudformation describe-stacks \
+    --stack-name aws-sam-ocr-pipeline-pipeline \
+    --query 'Stacks[].Outputs'
+```
+
+## Release through the newly built Pipeline
+
+Although CodePipeline will orchestrate this 3-environment CI/CD pipeline we need to learn how to integrate our toolchain to fit the following sections:
+
+> **Source code**
+
+All you need to do here is to initialize a local `git repository` for your existing service if you haven't done already and connect to the `git repository` that you retrieved in the previous section.
+
+```bash
+git init
+```
+
+Next, add a new Git Origin to connect your local repository to the remote repository:
+* [Git Instructions for HTTPS access](https://help.github.com/articles/adding-a-remote/)
+
+> **Build steps**
+
+This Pipeline expects `buildspec.yaml` to be at the root of this `git repository` and **CodeBuild** expects will read and execute all sections during the Build stage.
+
+Open up `buildspec.yaml` using your favourite editor and customize it to your needs - Comments have been added to guide you what's needed
+
+> **Triggering a deployment through the Pipeline**
+
+The Pipeline will be listening for new git commits pushed to the `master` branch (unless you changed), therefore all we need to do now is to commit to master and watch our pipeline run through:
+
+```bash
+git add . 
+git commit -m ""Kicking the tires of my first CI/CD pipeline""
+git push origin master
+```"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;\ No newline at end of file
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+version: 0.2 
+# Buildspec Reference Doc: https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec-ref-syntax
+# run-as: Linux-user-name
+
+# env: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.env
+#   shell: shell-tag
+#   variables:
+#     key: ""value""
+#     key: ""value""
+#   parameter-store:
+#     key: ""value""
+#     key: ""value""
+#   exported-variables:
+#     - variable
+#     - variable
+#   secrets-manager:
+#     key: secret-id:json-key:version-stage:version-id
+#   git-credential-helper: no | yes
+
+# proxy: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.proxy
+#   upload-artifacts: no | yes
+#   logs: no | yes
+
+# batch: # https://docs.aws.amazon.com/codebuild/latest/userguide/batch-build-buildspec.html#build-spec.batch
+  # fast-fail: false | true
+  # build-list:
+  # build-matrix:
+  # build-graph:
+        
+phases:
+  install:
+    # run-as: Linux-user-name
+    # on-failure: ABORT | CONTINUE
+    runtime-versions:
+      python: 3.8
+    #   runtime: version
+    # commands:
+    #   - command
+    #   - command
+    # finally:
+    #   - command
+    #   - command
+  # pre_build:
+    # run-as: Linux-user-name
+    # on-failure: ABORT | CONTINUE
+    # commands:
+    #   - command
+    #   - command
+    # finally:
+    #   - command
+    #   - command
+  build:
+    # run-as: Linux-user-name
+    on-failure: ABORT
+    commands:
+      - echo ""Starting SAM packaging `date` in `pwd`""
+      - aws cloudformation package --template-file template.yaml --s3-bucket $BUILD_OUTPUT_BUCKET --output-template-file packaged.yaml
+    # finally:
+    #   - command
+    #   - command
+  post_build:
+    # run-as: Linux-user-name
+    # on-failure: ABORT | CONTINUE
+    commands:
+      - echo ""SAM packaging completed on `date`""
+    # finally:
+    #   - command
+    #   - command
+
+# reports: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.reports
+#   report-group-name-or-arn:
+#     files:
+#       - location
+#       - location
+#     base-directory: location
+#     discard-paths: no | yes
+#     file-format: report-format
+artifacts: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.artifacts
+  files:
+    - packaged.yaml
+    # - location
+  name: artifact-name
+  discard-paths: yes
+  # base-directory: location
+  # exclude-paths: excluded paths
+  # enable-symlinks: no | yes
+  # s3-prefix: prefix
+  # secondary-artifacts:
+  #   artifactIdentifier:
+  #     files:
+  #       - location
+  #       - location
+  #     name: secondary-artifact-name
+  #     discard-paths: no | yes
+  #     base-directory: location
+  #   artifactIdentifier:
+  #     files:
+  #       - location
+  #       - location
+  #     discard-paths: no | yes
+  #     base-directory: location
+# cache: # https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec.cache
+#   paths:
+#     # - path
+#     # - path
\ No newline at end of file"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+AWSTemplateFormatVersion: 2010-09-09
+Description: >
+
+    This template generates a generic 3-environment CI/CD Pipeline for Serverless Apps that use SAM (Serverless Application Model).
+
+    Charges may apply for AWS Services utilized - Below are a summary for your convenience:
+
+      GitHub: Manages and Stores your service source code (Git repository)
+      Amazon S3: Manages CodeBuild Artifacts as well as Cache for subsequent runs when defined in the build spec
+      AWS CodeBuild: Manages and Runs builds specified under buildspec.yaml
+      AWS CodePipeline: Manages and Runs the Continuous Integration and Continuous Deployment pipeline
+      AWS CloudFormation: Manages SAM templates and creates the Infrastructure necessary for each environment
+      AWS IAM: Manages Identity and Access across Services outlined above
+
+
+Parameters:
+
+    GithubRepo:
+      Description: Gitub Repository name
+      Type: AWS::SSM::Parameter::Value<String>
+      Default: /service/aws-sam-ocr-pipeline/github/repo
+
+    GithubToken:
+      Description: Github OAuth Token with full permissions on admin:repo_hook and repo
+      Type: AWS::SSM::Parameter::Value<String>
+      NoEcho: true
+      Default: /service/aws-sam-ocr-pipeline/github/token
+
+    GithubUser:
+      Description: Github user where the repository lives
+      Type: AWS::SSM::Parameter::Value<String>
+      Default: /service/aws-sam-ocr-pipeline/github/user
+
+
+Resources:
+
+ ######   #######  ##     ## ########   ######  ######## 
+##    ## ##     ## ##     ## ##     ## ##    ## ##       
+##       ##     ## ##     ## ##     ## ##       ##       
+ ######  ##     ## ##     ## ########  ##       ######   
+      ## ##     ## ##     ## ##   ##   ##       ##       
+##    ## ##     ## ##     ## ##    ##  ##    ## ##       
+ ######   #######   #######  ##     ##  ######  ########
+
+    # CodeBuild project and resources (S3 Bucket for build artifacts, Role, Project)
+    BuildArtifactsBucket:
+        Type: AWS::S3::Bucket
+        Properties:
+          BucketEncryption:
+            ServerSideEncryptionConfiguration:
+              - ServerSideEncryptionByDefault:
+                  SSEAlgorithm: AES256
+          Tags: 
+            - 
+              Key: ""Stack""
+              Value: !Ref AWS::StackName
+            -
+              Key: ""Project""
+              Value: aws-sam-ocr-pipeline
+        DeletionPolicy: Retain
+        UpdateReplacePolicy: Retain
+
+########  ##     ## #### ##       ########  
+##     ## ##     ##  ##  ##       ##     ## 
+##     ## ##     ##  ##  ##       ##     ## 
+########  ##     ##  ##  ##       ##     ## 
+##     ## ##     ##  ##  ##       ##     ## 
+##     ## ##     ##  ##  ##       ##     ## 
+########   #######  #### ######## ########  
+
+    CodeBuildProject:
+        Type: AWS::CodeBuild::Project
+        Properties:
+            Name: aws-sam-ocr-pipeline
+            Description: Build project for the aws-sam-ocr-pipeline
+            Artifacts:
+              Type: CODEPIPELINE
+            Environment: 
+                Type: LINUX_CONTAINER
+                ComputeType: BUILD_GENERAL1_SMALL
+                Image: aws/codebuild/amazonlinux2-x86_64-standard:2.0 # More info on Images: https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html
+                EnvironmentVariables:
+                  - 
+                    Name: BUILD_OUTPUT_BUCKET
+                    Value: !Ref BuildArtifactsBucket
+            Cache:
+              Type: S3
+              Location: !Sub ${BuildArtifactsBucket}/codebuild-cache
+            ServiceRole: !GetAtt CodeBuildServiceRole.Arn
+            Source: 
+                Type: CODEPIPELINE
+            Tags: 
+              - 
+                Key: ""Stack""
+                Value: !Ref AWS::StackName
+              -
+                Key: ""Project""
+                Value: aws-sam-ocr-pipeline
+
+########  #### ########  ######## ##       #### ##    ## ######## 
+##     ##  ##  ##     ## ##       ##        ##  ###   ## ##       
+##     ##  ##  ##     ## ##       ##        ##  ####  ## ##       
+########   ##  ########  ######   ##        ##  ## ## ## ######   
+##         ##  ##        ##       ##        ##  ##  #### ##       
+##         ##  ##        ##       ##        ##  ##   ### ##       
+##        #### ##        ######## ######## #### ##    ## ######## 
+
+    Pipeline:
+        Type: AWS::CodePipeline::Pipeline
+        Properties:
+            ArtifactStore: 
+                Location: !Ref BuildArtifactsBucket
+                Type: S3
+            Name: aws-sam-ocr-pipeline
+            RoleArn: !GetAtt CodePipelineExecutionRole.Arn
+            Stages:
+                - Name: Source
+                  Actions:
+                    - Name: SourceCodeRepo
+                      ActionTypeId:
+                      # More info on Possible Values: https://docs.aws.amazon.com/codepipeline/latest/userguide/reference-pipeline-structure.html#action-requirements
+                        Category: Source
+                        Owner: ThirdParty
+                        Provider: GitHub
+                        Version: ""1""
+                      Configuration:
+                        Owner: !Ref GithubUser
+                        Repo: !Ref GithubRepo
+                        Branch: main
+                        OAuthToken: !Ref GithubToken
+                      OutputArtifacts:
+                        - Name: SourceCodeAsZip
+                      RunOrder: 1
+                - Name: Build
+                  Actions:
+                    - Name: CodeBuild
+                      ActionTypeId:
+                        Category: Build
+                        Owner: AWS
+                        Provider: CodeBuild
+                        Version: ""1""
+                      Configuration:
+                        ProjectName: !Ref CodeBuildProject
+                      InputArtifacts:
+                        - Name: SourceCodeAsZip
+                      OutputArtifacts:
+                        - Name: BuildArtifactAsZip
+                - Name: Beta
+                  Actions:
+                    - Name: CreateChangeSet
+                      ActionTypeId:
+                        Category: Deploy
+                        Owner: AWS
+                        Provider: CloudFormation
+                        Version: ""1""
+                      Configuration:
+                      # More info on Possible Values for Cloudformation: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/continuous-delivery-codepipeline-action-reference.html#w2ab2c13c13b9
+                        ActionMode: CHANGE_SET_REPLACE
+                        RoleArn: !GetAtt CloudFormationExecutionRole.Arn
+                        StackName: aws-sam-ocr-pipeline-Beta
+                        ChangeSetName: aws-sam-ocr-pipeline-ChangeSet-Beta
+                        TemplatePath: BuildArtifactAsZip::packaged.yaml
+                        Capabilities: CAPABILITY_IAM
+                      InputArtifacts:
+                        - Name: BuildArtifactAsZip
+                      RunOrder: 1
+                    - Name: ExecuteChangeSet
+                      ActionTypeId:
+                        Category: Deploy
+                        Owner: AWS
+                        Provider: CloudFormation
+                        Version: ""1""
+                      Configuration:
+                        ActionMode: CHANGE_SET_EXECUTE
+                        RoleArn: !GetAtt CloudFormationExecutionRole.Arn
+                        StackName: aws-sam-ocr-pipeline-Beta
+                        ChangeSetName: aws-sam-ocr-pipeline-ChangeSet-Beta
+                      OutputArtifacts:
+                        - Name: aws-sam-ocr-pipelineBetaChangeSet
+                      RunOrder: 2
+                - Name: Gamma
+                  Actions:
+                    - Name: CreateChangeSet
+                      ActionTypeId:
+                        Category: Deploy
+                        Owner: AWS
+                        Provider: CloudFormation
+                        Version: ""1""
+                      Configuration:
+                        ActionMode: CHANGE_SET_REPLACE
+                        RoleArn: !GetAtt CloudFormationExecutionRole.Arn
+                        StackName: aws-sam-ocr-pipeline-Gamma
+                        ChangeSetName: aws-sam-ocr-pipeline-ChangeSet-Gamma
+                        TemplatePath: BuildArtifactAsZip::packaged.yaml
+                        Capabilities: CAPABILITY_IAM
+                      InputArtifacts:
+                        - Name: BuildArtifactAsZip
+                      RunOrder: 1
+                    - Name: ExecuteChangeSet
+                      ActionTypeId:
+                        Category: Deploy
+                        Owner: AWS
+                        Provider: CloudFormation
+                        Version: ""1""
+                      Configuration:
+                        ActionMode: CHANGE_SET_EXECUTE
+                        RoleArn: !GetAtt CloudFormationExecutionRole.Arn
+                        StackName: aws-sam-ocr-pipeline-Gamma
+                        ChangeSetName: aws-sam-ocr-pipeline-ChangeSet-Gamma
+                      OutputArtifacts:
+                        - Name: aws-sam-ocr-pipelineGammaChangeSet
+                      RunOrder: 2
+                - Name: Prod
+                  Actions:
+                    - Name: DeploymentApproval
+                      ActionTypeId:
+                        Category: Approval
+                        Owner: AWS
+                        Provider: Manual
+                        Version: ""1""
+                      RunOrder: 1
+                    - Name: CreateChangeSet
+                      ActionTypeId:
+                        Category: Deploy
+                        Owner: AWS
+                        Provider: CloudFormation
+                        Version: ""1""
+                      Configuration:
+                        ActionMode: CHANGE_SET_REPLACE
+                        RoleArn: !GetAtt CloudFormationExecutionRole.Arn
+                        StackName: aws-sam-ocr-pipeline-Prod
+                        ChangeSetName: aws-sam-ocr-pipeline-ChangeSet-Prod
+                        TemplatePath: BuildArtifactAsZip::packaged.yaml
+                        Capabilities: CAPABILITY_IAM
+                      InputArtifacts:
+                        - Name: BuildArtifactAsZip
+                      RunOrder: 2
+                    - Name: ExecuteChangeSet
+                      ActionTypeId:
+                        Category: Deploy
+                        Owner: AWS
+                        Provider: CloudFormation
+                        Version: ""1""
+                      Configuration:
+                        ActionMode: CHANGE_SET_EXECUTE
+                        RoleArn: !GetAtt CloudFormationExecutionRole.Arn
+                        StackName: aws-sam-ocr-pipeline-Prod
+                        ChangeSetName: aws-sam-ocr-pipeline-ChangeSet-Prod
+                      OutputArtifacts:
+                        - Name: aws-sam-ocr-pipelineProdChangeSet
+                      RunOrder: 3
+
+
+####    ###    ##     ## 
+ ##    ## ##   ###   ### 
+ ##   ##   ##  #### #### 
+ ##  ##     ## ## ### ## 
+ ##  ######### ##     ## 
+ ##  ##     ## ##     ## 
+#### ##     ## ##     ## 
+
+    CodeBuildServiceRole:
+        Type: AWS::IAM::Role
+        Properties:
+            AssumeRolePolicyDocument:
+                Version: '2012-10-17'
+                Statement:
+                  - Action: 
+                      - 'sts:AssumeRole'
+                    Effect: Allow
+                    Principal:
+                      Service:
+                        - codebuild.amazonaws.com
+            Path: /
+            Policies:
+                - PolicyName: CodeBuildLogs
+                  PolicyDocument:
+                    Version: '2012-10-17'
+                    Statement:
+                      - 
+                        Effect: Allow
+                        Action:
+                          - 'logs:CreateLogGroup'
+                          - 'logs:CreateLogStream'
+                          - 'logs:PutLogEvents'
+                        Resource:
+                          - !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/codebuild/aws-sam-ocr-pipeline'
+                          - !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/codebuild/aws-sam-ocr-pipeline:*'
+                - PolicyName: CodeBuildArtifactsBucket
+                  PolicyDocument:
+                    Version: '2012-10-17'
+                    Statement:
+                      - 
+                        Effect: Allow
+                        Action: 
+                          - 's3:GetObject'
+                          - 's3:GetObjectVersion'
+                          - 's3:PutObject'
+                        Resource:
+                          - !Sub 'arn:aws:s3:::${BuildArtifactsBucket}/*'
+                - PolicyName: CodeBuildParameterStore
+                  PolicyDocument:
+                    Version: '2012-10-17'
+                    Statement:
+                      -
+                        Effect: Allow
+                        Action: 'ssm:GetParameters'
+                        Resource: '*'
+
+
+    CloudFormationExecutionRole:
+      Type: AWS::IAM::Role
+      Properties:
+        AssumeRolePolicyDocument:
+          Version: '2012-10-17'
+          Statement:
+            Action: 'sts:AssumeRole'
+            Effect: Allow
+            Principal:
+              Service: cloudformation.amazonaws.com
+        Path: /
+        ManagedPolicyArns:
+          - 'arn:aws:iam::aws:policy/AdministratorAccess'
+
+
+    CodePipelineExecutionRole:
+        Type: AWS::IAM::Role
+        Properties:
+            AssumeRolePolicyDocument:
+                Version: '2012-10-17'
+                Statement:
+                  - 
+                    Action: 
+                        - 'sts:AssumeRole'
+                    Effect: Allow
+                    Principal:
+                      Service: 
+                        - codepipeline.amazonaws.com
+            Path: /
+            Policies:
+                - PolicyName: CodePipelineAccess
+                  PolicyDocument:
+                    Version: '2012-10-17'
+                    Statement:
+                        - 
+                            Effect: Allow
+                            Action:
+                                - 'iam:PassRole'
+                                - 'lambda:InvokeFunction'
+                                - 'lambda:ListFunctions'
+                                - 'lambda:InvokeAsyc'
+                            Resource: '*'
+                - PolicyName: CodePipelineCodeAndArtifactsS3Bucket
+                  PolicyDocument:
+                    Version: '2012-10-17'
+                    Statement:
+                      - 
+                        Effect: Allow
+                        Action: 's3:*'
+                        Resource: !Sub 'arn:aws:s3:::${BuildArtifactsBucket}/*'
+                - PolicyName: CodePipelineCodeBuildAndCloudformationAccess
+                  PolicyDocument:
+                    Version: '2012-10-17'
+                    Statement:
+                      - 
+                        Effect: Allow
+                        Action: 
+                          - 'codebuild:StartBuild'
+                          - 'codebuild:BatchGetBuilds'
+                        Resource: 
+                          - !Sub 'arn:aws:codebuild:${AWS::Region}:${AWS::AccountId}:project/${CodeBuildProject}'
+                      - 
+                        Effect: Allow
+                        Action: 
+                          - 'cloudformation:CreateStack'
+                          - 'cloudformation:DescribeStacks'
+                          - 'cloudformation:DeleteStack'
+                          - 'cloudformation:UpdateStack'
+                          - 'cloudformation:CreateChangeSet'
+                          - 'cloudformation:ExecuteChangeSet'
+                          - 'cloudformation:DeleteChangeSet'
+                          - 'cloudformation:DescribeChangeSet'
+                          - 'cloudformation:SetStackPolicy'
+                          - 'cloudformation:SetStackPolicy'
+                          - 'cloudformation:ValidateTemplate'
+                        Resource: 
+                          - !Sub 'arn:aws:cloudformation:${AWS::Region}:${AWS::AccountId}:stack/aws-sam-ocr-pipeline*/*'
+                          - !Sub 'arn:aws:cloudformation:${AWS::Region}:aws:transform/Serverless-2016-10-31'
+
+
+Outputs:
+
+
+    GitHubRepositoryHttpUrl:
+      Description: GitHub Git repository
+      Value: !Sub https://github.com/${GithubUser}/${GithubRepo}.git
+
+    GitHubRepositorySshUrl:
+      Description: GitHub Git repository
+      Value: !Sub git@github.com:${GithubUser}/${GithubRepo}.git
+  
+    BuildArtifactS3Bucket:
+      Description: Amazon S3 Bucket for Pipeline and Build artifacts
+      Value: !Ref BuildArtifactsBucket
+
+    CodeBuildProject:
+      Description: CodeBuild Project name
+      Value: !Ref CodeBuildProject
+
+    CodePipeline:
+      Description: AWS CodePipeline pipeline name
+      Value: !Ref Pipeline
+
+    CodeBuildIAMRole:
+      Description: CodeBuild IAM Role
+      Value: !GetAtt CodeBuildServiceRole.Arn
+
+    CloudformationIAMRole:
+      Description: Cloudformation IAM Role
+      Value: !GetAtt CloudFormationExecutionRole.Arn
+
+    CodePipelineIAMRole:
+      Description: CodePipeline IAM Role
+      Value: !GetAtt CodePipelineExecutionRole.Arn"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+from __future__ import print_function
+import boto3
+from decimal import Decimal
+import json
+import urllib
+import uuid
+import datetime
+import time
+import os
+
+rekognition_client = boto3.client('rekognition')
+s3_client = boto3.client('s3')
+dynamo_client = boto3.client('dynamodb')
+
+# Get the table name from the Lambda Environment Variable
+table_name = os.environ['TABLE_NAME']
+
+# --------------- Helper Functions to call Rekognition APIs ------------------
+
+def detect_text(bucket, key):
+    response = rekognition_client.detect_text(Image={""S3Object"": {""Bucket"": bucket, ""Name"": key}})
+    return response
+
+def detect_labels(bucket, key):
+    response = rekognition_client.detect_labels(Image={""S3Object"": {""Bucket"": bucket, ""Name"": key}})
+    return response
+
+# --------------- Main handler ------------------
+def lambda_handler(event, context):
+    '''
+    Uses Rekognition APIs to detect text and labels for objects uploaded to S3
+    and store the content in DynamoDB.
+    '''
+    # Log the the received event locally.
+    # print(""Received event: "" + json.dumps(event, indent=2))
+
+    # Get the object from the event.
+    bucket = event['Records'][0]['s3']['bucket']['name']
+    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])
+
+    try:
+        # Call rekognition DetectText API to detect Text in S3 object.
+        response = detect_text(bucket, key)
+        textDetections = [text['DetectedText'] for text in response['TextDetections']]
+
+        # Log text detected.
+        # for text in textDetections:
+        #    print (text)
+
+        # Call rekognition DetectLabels API to detect labels in S3 object.
+        response = detect_labels(bucket, key)
+        labels = [{label_prediction['Name']: Decimal(str(label_prediction['Confidence']))} for label_prediction in response['Labels']]
+        
+        # Log labels detected.
+        # for label in labels:
+        #    print (label)
+
+        # Get the timestamp.
+        ts = time.time()
+        timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')
+
+        # Write to DynamoDB.
+        table = boto3.resource('dynamodb').Table(table_name)
+        item={'id':key, 'DateTime':timestamp, 'Labels':labels, 'Text':textDetections}
+        table.put_item(Item=item)
+
+        return 'Success'
+    except Exception as e:
+        print(""Error processing object {} from bucket {}. Event {}"".format(key, bucket, json.dumps(event, indent=2)))
+        raise e"
KO;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;\ No newline at end of file
OK;39;ferlellws;aws_sam_ocr;cde9a96b3b20009320a5cd9a140bd74b21fd00fd;Updated timeout and memory size;"+AWSTemplateFormatVersion: '2010-09-09'
+Transform: 'AWS::Serverless-2016-10-31'
+
+Description: SAM app that uses Rekognition APIs to detect text in S3 Objects and stores labels in DynamoDB.
+
+Resources:
+  DetectTextInImage:
+    Type: 'AWS::Serverless::Function'
+    Properties:
+      Handler: src/app.lambda_handler
+      Runtime: python3.9
+      CodeUri: .
+      Description: Uses Rekognition APIs to detect text in S3 Objects and stores the text and labels in DynamoDB.
+      MemorySize: 256
+      Timeout: 45
+      Environment:
+        Variables:
+          TABLE_NAME:
+            Ref: ResultsTable
+      Policies:
+        - Version: '2012-10-17'
+          Statement:
+            - Effect: Allow
+              Action:
+                - 's3:GetObject'
+              Resource: 'arn:aws:s3:::*'
+            - Effect: Allow
+              Action:
+                - 's3:PutObject'
+              Resource: !GetAtt FailedImageBucket.Arn
+            - Effect: Allow
+              Action:
+                - 'rekognition:DetectText'
+                - 'rekognition:DetectLabels'
+              Resource: '*'
+            - Effect: Allow
+              Action:
+                - 'dynamodb:GetItem'
+                - 'dynamodb:PutItem'
+                - 'dynamodb:Scan'
+                - 'dynamodb:UpdateItem'
+              Resource:
+                'Fn::Join':
+                  - ''
+                  - - 'arn:aws:dynamodb:'
+                    - Ref: 'AWS::Region'
+                    - ':'
+                    - Ref: 'AWS::AccountId'
+                    - ':table/'
+                    - Ref: ResultsTable
+      Events:
+        BucketEvent1:
+          Type: S3
+          Properties:
+            Bucket:
+              Ref: SourceImageBucket
+            Events:
+              - 's3:ObjectCreated:*'
+  
+  SourceImageBucket:
+    Type: 'AWS::S3::Bucket'
+
+  FailedImageBucket:
+    Type: 'AWS::S3::Bucket'
+
+  ResultsTable:
+    Type: AWS::Serverless::SimpleTable
\ No newline at end of file"
